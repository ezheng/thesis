% !TEX root = ../thesis_heinly.tex

\begin{center}
\vspace*{46pt}
\currentpdfbookmark{ABSTRACT}{bk:abstract}
\textbf{ABSTRACT}
\vspace{4pt}

\begin{singlespace}
\thesisauthor: \thesistitle \\
(Under the direction of \thesisadvisors)
\vspace{10pt}
\end{singlespace}
\end{center}



%3D reconstrcution Recovering 3D information from imagery is an important task in the field of computer vision.
%With the bursting number of images and videos available on the Internet, it has been of interest to the computer vision community to perform 3D reconstruction of a scene from such data for further applications. Though 3D reconstruction, a process that recovers the 3D information of a scene via images, is a traditional topic in computer vision, some of the challenging problems still remain partially solved or even unsolved. This is especially true when using crowd-sourced data with heterogeneous properties, such as images with random occlusions and videos with unknown temporal overlap. Moreover, most existing methods only target the problem of static scene reconstruction, but fail on the dynamic part due to additional challenges such as non-current captures. To push forward the research frontier for image based 3D modeling, this dissertation focuses on the problem of static as well as dynamic object reconstruction from unstructured images or unsynchronized videos. 

%The problem of 3D reconstruction from imagery aims at recovering 3D information of a scene based on image colors.

The goal of image-based 3D reconstruction is to build up a spatial understanding of the world from a collection of images. For applications that seek to model generic real-world scenes, it is important that the reconstruction methods used are able to characterize both static scene elements (\eg~trees and buildings) as well as dynamic objects (\eg~cars and pedestrians). However, due to many inherent ambiguities in the reconstruction problem, recovering this 3D information with accuracy, robustness, and efficiency is a considerable challenge. To advance the research frontier for image-based 3D modeling, this dissertation focuses on three challenging problems in static scene and dynamic object reconstruction. 

We first target the problem of static scene depthmap estimation from crowd-sourced datasets (\ie~photos collected from the Internet). While achieving high-quality depthmaps using images taken under a controlled environment is already a difficult task, heterogeneous crowd-sourced data presents a unique set of challenges for multi-view depth estimation, including varying illumination and occasional occlusions. We propose a depthmap estimation method that demonstrates high accuracy, robustness, and scalability on a large number of photos collected from the Internet.
 
Compared to static scene reconstruction, the problem of dynamic object reconstruction from monocular images is fundamentally ambiguous when not imposing any additional assumptions. This is because having only a single observation of an object is insufficient for valid 3D triangulation, which typically requires concurrent observations of the object from multiple viewpoints. Assuming that dynamic objects of the same class (\eg all the pedestrians walking on a sidewalk) move in a common path in the real world, we develop a method that estimates the 3D positions of the dynamic objects from unstructured monocular images. Experiments on both synthetic and real datasets illustrate the solvability of the problem and the effectiveness of our approach.

Finally, we address the problem of dynamic object reconstruction from a set of unsynchronized videos capturing the same dynamic event, instead of using monocular images as input. This problem is of great interest because, due to the increased availability of portable capture devices, captures using multiple unsynchronized videos are common in the real world. To resolve the difficulty that arises from non-concurrent captures and unknown temporal overlap among video streams, we propose a self-expressive dictionary learning framework, where the dictionary entries are defined as the collection of temporally varying structures. The experimental results show that this novel approach effectively solves the previously unsolved problem.


\clearpage
