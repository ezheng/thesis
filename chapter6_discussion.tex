%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Discussion}
\label{ch:discussion}

This dissertation has presented efficient methods to robustly handle the data association problem in large-scale structure-from-motion systems.
In \chref{streaming} we proposed a new paradigm for connected component discovery in large-scale photo collections.
This method is based on a streaming framework, and we demonstrated its effectiveness on a world-scale 100 million image dataset \cite{yahoo_100m, thomee2015_data_challenges}.
In \chref{duplicate_structure} we proposed a state-of-the-art method to perform disambiguation in the case of duplicate scene structures.
Here, our method is able to identify the errors in a reconstructed model, and correct for those errors resulting in an accurate representation of the scene.
Finally, in \chref{lcc}, we proposed modifications to the duplicate structure disambiguation method to improve its efficiency by exploiting the co-occurrence information present in the scene's geometry.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Future Directions}

In regard to the area of research to which this dissertation pertains, we propose several different avenues for future work on these topics.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection[Extensions to the Streaming Paradigm for Connected Component Discovery]{Extensions to the Streaming Paradigm for Connected Component Discovery}
\label{sec:streaming_extensions}

One of the first useful extensions to this work would be to make a second pass through the input dataset (assuming that it is static).
Here, the intention would be to recover a higher fraction of the registerable images in the dataset.
To make the processing more efficient, one could experiment with the number of nearest neighbors on which each streamed image attempts to register.
For example, the first pass could be modified to only match to the first nearest neighbor, so that the output is only a set of image clusters (and not connected components).
Then, the second pass could use the current existing strategy of matching to two neighbors, to allow for the linking of clusters into components.
Furthermore, and trivially, the second pass through the images would not need to recompute SIFT features, avoiding the bottleneck of feature computation.

Another useful strategy of the second pass would be to focus on those sets of images that already have been clustered.
Specifically, when streaming through on the second pass, the inverted index of the vocabulary tree could be initialized with the iconic images of the final clusters, and any image that does not successfully register to one of these iconic images would be immediately discarded.
To improve the diversity of the recovered images, and to avoid biasing toward those images that have already been recovered, we could augment the set of existing iconic images with additional images from the cluster that are sufficiently diverse.
For instance, a cluster image that successfully registered, but had a large variation in its bag-of-words representation could be used as an additional, diversified representation of the cluster, to help register those images that were not sufficiently similar to the cluster's single, original iconic image.

One of the current limitations of the streaming pipeline is that structure-from-motion is not run until the streaming connected component discovery concludes.
It would be useful to visualize the recovered 3D geometry as it is being discovered, and it could actually increase the performance of the system.
For instance, as opposed to waiting until the end of the streaming, structure-from-motion could be run for each cluster as it forms.
To promote stable and accurate results, the reconstruction could be initialized only once a sufficient initial pair of images is found \cite{beder2006_initial_pair}.
This could naturally be incorporated as a test between the iconic image of a cluster, and each new image that is added to it.
Once the reconstruction is initialized, instead of performing essential matrix estimation for each new candidate image, a more efficient 2D-3D registration technique could be employed (yielding faster runtimes).

To represent the structure-from-motion model in the vocabulary tree, each of its 3D points can be represented either by a single SIFT descriptor from an image that observes it, or by the centers computed from a mean-shift clustering of all the SIFT descriptors viewing that point \cite{pollefeys2010_challenges_sfm}.
To avoid biasing toward the already reconstructed parts of the cluster, the unreconstructed features from the iconic image could additionally be used in the cluster's bag-of-words representation (just as the unregistered features of an iconic image are used in its representation).

One negative aspect in attempting to perform structure-from-motion during the streaming process is an increased memory burden for those clusters that have yet to be reconstructed.
For instance, one scheme would be to keep the feature locations and registration information in memory for all cluster images, so that when a cluster is able to reconstruct, it can use information from all of the cluster images to refine its representation.
However, storing this information will greatly increase each cluster's representation in memory, which may be prohibitive.
To alleviate this issue, a cluster could discard information about its cluster images as usual, and only start to retain additional information once a successful two-view reconstruction has been initialized for the cluster.

This above strategy of leveraging structure-from-motion during the streaming process could also be easily combined with a two-pass implementation.
For instance, the first pass could perform the clustering as normal, and upon completion, structure-from-motion would be run.
Then, on the second pass through the dataset, efficient 2D-3D registration could be used, greatly speeding up the computation in that second pass.
In this scheme, by only allowing the images in the second pass to register to existing SfM models, the focus would be on growing and combining the models, and any image that does not register to one of the models would be immediately discarded.

Another extension would be to incorporate an online learning strategy that determines what type of images are registerable in the dataset.
The motivation for this is that image registration is one of the largest (if not the largest) computational bottlenecks of the system.
Therefore, any improvement to its efficiency will improve the overall runtime of the system.
To accomplish the goals of learning what type of images are registerable, we could use a method similar to \cite{raguram2012_improved_verification}, where a classifier is trained based on the current set of registerable and unregisterable images that have been processed.
Once the classifier is trained to a sufficient confidence, images in the stream that have too low of a score (as determined by the classifier) can automatically be skipped or only matched to a reduced subset of their nearest neighbors (\ie their first nearest neighbor) to avoid further computation.

Continuing the goal of reducing the computational burden of image registration, we could test the usefulness of using a cascade of image registration techniques.
For instance, we could first test for the existence of a valid affine transform or a global camera rotation (assuming all features are at an infinite distance) before attempting to test for an essential matrix.
The reasoning for attempting these methods is that they are very easy to compute from their minimal samples, avoiding the expensive operations required to solve for an essential matrix \cite{nister2003_five_point}.
Additionally, they have a smaller minimal sample size, which greatly reduces the number of required RANSAC iterations to achieve the same confidence and inlier rate.
While the number of inliers to one of these simplified models would be lower, the reduced sample size can yield a reduced number of iterations and computation time.

In the case when essential matrix estimation needs to be performed between two images, estimating the essential matrix from its minimal set of five points is a non-trivial operation \cite{nister2003_five_point}.
Several recent works have reported success in replacing the five-point algorithm with efficient minimal solvers \cite{helmke2007_essential_gauss_newton, rosten2010_ransac_iterative_solvers, botterill2011_fast_ransac_essential, lui2013_iterative_five_point}.
In these cases, methods reported average speed improvements ranging from a few percent up to two or three times faster than the standard implementation.
We wrote an initial implementation of \cite{lui2013_iterative_five_point}, and it is indeed faster, but currently only for images pairs with fewer than 70\% inliers.
Therefore, we could continue to investigate these methods, optimize their implementation, and even propose a hybrid approach that would switch between the standard five-point method and an iterative solver once RANSAC has reasonable confidence that the inlier rate is below a particular threshold (which would be after a particular number of RANSAC iterations).

To improve the speed at which RANSAC finds a valid solution (assuming one exists), we could leverage the work by \citet{sattler2009_scramsac} in which they propose a spatial consistency filter prior to estimation in RANSAC, which they term SCRAMSAC \cite{sattler2009_scramsac}.
Here, candidate feature matches are pruned when they do not have a sufficient number of nearby matches mapping to similar parts of the two images.
The end result is that the overall inlier rate is typically increased, allowing RANSAC to more rapidly find the valid solution.
For instance, speed improvements up to two orders of magnitude were demonstrated when employing this strategy \cite{sattler2009_scramsac}.
While we would test SCRAMSAC's applicability as proposed in its paper \cite{sattler2009_scramsac}, we would also test it in conjunction with PROSAC \cite{chum2005_prosac}, which leverages a better sampling scheme when some prior information is known about the quality of each of the candidate feature matches.
One of the potential shortcomings we have observed with SCRAMSAC is that it can discard too many of its candidate feature matches in low-inlier scenarios.
Therefore, by using the spatial consistency score leveraged in SCRAMSAC, we can sort the candidate matches, and use them in a PROSAC-style sampling.
This would yield the benefits of the spatial consistency filter, while at the same time preserving the entire candidate match set.
When testing the use of PROSAC, however, we would need to take care to avoid biasing the results toward degenerate configurations, as mentioned in \citet{sattler2009_scramsac}.

Apart from image registration (RANSAC and essential matrix estimation), feature computation is the other large bottleneck of the streaming system even when using multiple GPUs and a GPU-enabled SIFT implementation \cite{wu2007_siftgpu}.
Therefore, by using a feature which is more easy to compute, the computational burden of this stage in the pipeline could be greatly reduced, as well as reducing the need for multiple, expensive GPUs.
Several binary features have recently been proposed, some of which provide excellent performance in certain scenarios \cite{heinly2012_binary_descriptors}.
Specifically, we would investigate the use of BRIEF \cite{calonder2010_brief} in conjunction with Harris corners \cite{harris1988_corner}.
Both of these are very easy to compute, though in combination, no scale or rotation invariance is provided.
Our motivation here is that in large-scale crowdsourced photo collections, many people will take photos in either portrait or landscape orientation, obviating the need for rotation invariance (except to find correspondences between these two orientations).
Furthermore, with such a large collection of images, there will be many different views of the same scene at different scales, which could be linked transitively when using a detector/descriptor pairing that is not scale invariant.
Therefore, the streaming system could be run using this feature combination, and only once useful image clusters are found, would SIFT features \cite{lowe2004_sift, wu2007_siftgpu} be extracted to link clusters of widely differing scales or orientations.

If a descriptor that was not rotation invariant were to be used for image registration, essential matrix estimation could be modified to take advantage of this fact.
Specifically, because the descriptors enforce a similar 2D rotation between the images, we can assume that there is an insignificant amount of relative rotation around the camera's viewing directions.
Because this reduces the number of degrees of freedom in the relative pose (from five to four), a smaller minimal sample size could be used in RANSAC, yielding a faster runtime.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Extensions to Ambiguous Structure Disambiguation}

Currently, one area of weakness in the ambiguous structure disambiguation methods is the scalability and runtime.
Even though the method of \chref{duplicate_structure} has linear complexity in the number of cameras, and the method of \chref{lcc} has linear complexity in the number of points, the computation time can still be non-trivial for large datasets.
Specifically, we would like to maintain the excellent disambiguation ability of the first method, but drastically improve its speed (as opposed to the $lcc$ based method which sacrifices some disambiguation ability).
One modification that could be made would be to leverage the edge costs in the minimum spanning tree.
Currently, once the minimum spanning tree is constructed, only its structure is used and its weights are ignored.
Upon inspection, the edge with the most conflicting observations is also usually the edge with the highest cost in the minimum spanning tree.
Therefore, the edge cost could be used as a prior, biasing the search toward these edges.

Another way to speed up the method of \chref{duplicate_structure} is through a breadth-first search of the camera pairs associated with each minimum spanning tree edge.
Currently, each edge in the minimum spanning tree results in up to $s=100$ camera pairs being evaluated for conflicting observations.
A smaller number of camera pairs could initially be evaluated at each minimum spanning tree edge, and then only those that show the most conflict could be selected for further evaluation, in a recursive, breadth-first manner.
This search could also be biased by the minimum spanning tree edge weights as mentioned above, to provide another prior as to which edges to focus the evaluation.

Another way to address the efficiency of the duplicate structure disambiguation is to expand upon the extension proposed in \secref{sparse_reconstruction_correction}.
Here, as opposed to processing the entire model at once, independent components are identified using the mean-shift algorithm over the sparse 3D geometry (projected to 2D space).
While this worked for the datasets on which it was tested, a more rigorous formulation and evaluation would prove useful.
For instance, as opposed to using mean-shift, images could be more explicitly grouped based on the visibility graph structure, so that cameras observing common content are the ones used for the disambiguation.
Furthermore, these groupings could allow the algorithm to run in parallel, as each group could be evaluated independently for conflict, and then a global merge operation could correct for any discovered errors.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Additional Research Directions}

We now propose two more general research topics related to structure-from-motion systems.

The first deals with many of the points brought up in \secref{streaming_extensions}, where image registration is a major bottleneck in structure-from-motion systems.
Specifically, the issue when two candidate images will not register, and thus consume the maximum number of RANSAC iterations.
While some of the proposed strategies will address this issue, efficient data association in large, unorganized photo collections is an open topic.
Therefore, we propose to leverage feature-based (similarity of visual words, similarity of underlying feature descriptors, \etc), geometry-based (similarity of spatial distribution of features, recurrence of common feature clusters, \etc), and classifier-based (learn models on useful feature and geometry-based configurations) methods to put better priors on the ability of two images to successfully register.
This would be in a similar vein of work as \citet{li2009_scale_feature_matching, lou2012_match_miner, mills2013_improved_feature_matching, hartmann2014_predicting_matchability, schoenberger2015_paige}.

The second topic deals with errors in the reconstructed structure-from-motion model.
While we already proposed a post-processing step to correct for errors due to duplicate or ambiguous structure, these are not the only errors that are present.
For instance, popular scenes that are imaged both during daytime and nighttime hours often result in separate 3D structures, or superimposed surfaces within the same model.
Additionally, temporary structures that are captured in many photos, such as scaffolding used for restoration, can cause the previously proposed duplicate structure disambiguation methods to incorrectly segment the model.
Given the success of the conflicting observations measure in the disambiguation of duplicate structure, and its underpinnings in reasoning about the geometric layout of the underlying scene, we propose to investigate additional reasoning or criteria which could be added to the structure-from-motion process in order to avoid the types of issues listed above.
Here, as opposed to blindly triangulating 3D points and registering cameras, additional geometric scene validity would be enforced to constrain the reconstruction \cite{furukawa2009_manhattan_stereo, gallup2010_planar_stereo, cohen2012_exploiting_symmetries, wu2012_schematic_reconstruction, bao2013_semantic_priors, hane2013_reconstruction_segmantation, hane2014_shape_priors}.
One potential way to incorporate these types of constraints in structure-from-motion is through the simultaneous use of dense estimation techniques (such as multi-view stereo methods).
The incorporation of this information could allow a reconstruction method to better verify if a newly aligned image conforms to the currently reconstructed scene, as several methods either directly report (or could be modified to report) on the confidence of the estimated depth information, or the reliable subset of images used to estimate the final depth for a particular pixel or region \cite{strecha2006_outlier_depth, goesele2007_commonunity_stereo, furukawa2010_pmvs, zheng2014_depthmap_estimation}.